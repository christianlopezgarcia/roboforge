{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec1167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure pip is up to date\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Install OpenCV\n",
    "!pip3 install opencv-python-headless numpy\n",
    "\n",
    "# Install PyTorch (CPU-only for Pi 4B)\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "# Install ultralytics (YOLO v8+)\n",
    "!pip3 install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9337a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you haven't installed yet\n",
    "# !pip install --upgrade pip\n",
    "# !pip install opencv-python-headless numpy ultralytics torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"Dependencies imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1299b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your trained model\n",
    "MODEL_PATH = \"trained_yolo_model/ODM-ver5.pt\"\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO(MODEL_PATH)\n",
    "print(\"YOLO model loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7acd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration parameters\n",
    "KNOWN_WIDTH_INCH = 1.0      # block width\n",
    "KNOWN_DISTANCE_INCH = 12.0  # place block at this distance for calibration\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "FOCAL_LENGTH = None\n",
    "\n",
    "print(\"Calibration: place a single block exactly 12 inches away and press SPACE\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    \n",
    "    results = model(frame)\n",
    "    annotated = results[0].plot()\n",
    "    \n",
    "    cv2.imshow(\"Calibration\", annotated)\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key & 0xFF == 32:  # SPACE key\n",
    "        boxes = results[0].boxes.xywh  # x_center, y_center, w, h\n",
    "        if len(boxes) > 0:\n",
    "            w_pixels = boxes[0][2].item()\n",
    "            FOCAL_LENGTH = (w_pixels * KNOWN_DISTANCE_INCH) / KNOWN_WIDTH_INCH\n",
    "            print(f\"✅ Focal length calibrated: {FOCAL_LENGTH:.2f} pixels\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"⚠️ No block detected. Try again\")\n",
    "    elif key & 0xFF == 27:  # ESC\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f7fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "KNOWN_WIDTH_INCH = 1.0\n",
    "KNOWN_DISTANCE_INCH = 12.0\n",
    "FOCAL_LENGTH = None\n",
    "\n",
    "# Load your model if not already loaded\n",
    "# model = YOLO(MODEL_PATH)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Camera not opened\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae788e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install opencv-python-headless matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf014b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from picamera2 import Picamera2\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "picam2 = Picamera2()\n",
    "picam2.start()\n",
    "\n",
    "while True:\n",
    "    frame = picam2.capture_array()  # returns a NumPy array\n",
    "    # frame is now an OpenCV BGR image\n",
    "    cv2.imshow(\"Preview\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "picam2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf61ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "KNOWN_WIDTH_INCH = 1.0\n",
    "KNOWN_DISTANCE_INCH = 12.0\n",
    "FOCAL_LENGTH = None\n",
    "\n",
    "# Load your model if not already loaded\n",
    "# model = YOLO(MODEL_PATH)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"Calibration: place a single block 12 inches away and press SPACE\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    start = time.time()\n",
    "    results = model(frame, verbose=False)  # suppress extra logs\n",
    "    end = time.time()\n",
    "    \n",
    "    # Annotate frame\n",
    "    annotated_frame = results[0].plot()\n",
    "    fps = 1 / (end - start)\n",
    "    cv2.putText(annotated_frame, f\"FPS: {fps:.2f}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # Convert BGR to RGB for Jupyter\n",
    "    annotated_frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display in Jupyter\n",
    "    clear_output(wait=True)\n",
    "    display(cv2.cvtColor(annotated_frame_rgb, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Check if any block detected\n",
    "    if len(results[0].boxes) > 0:\n",
    "        print(f\"Detected {len(results[0].boxes)} block(s)\")\n",
    "\n",
    "    key = input(\"Press 'c' to calibrate, 'q' to quit, Enter to continue... \").lower()\n",
    "    if key == 'c':\n",
    "        if len(results[0].boxes) > 0:\n",
    "            w_pixels = results[0].boxes.xywh[0][2].item()\n",
    "            FOCAL_LENGTH = (w_pixels * KNOWN_DISTANCE_INCH) / KNOWN_WIDTH_INCH\n",
    "            print(f\"✅ Focal length calibrated: {FOCAL_LENGTH:.2f} pixels\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"⚠️ No block detected, try again\")\n",
    "    elif key == 'q':\n",
    "        break\n",
    "\n",
    "cap.release() \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83996f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83739e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if FOCAL_LENGTH is not None:\n",
    "    print(\"⚠️ Focal length not calibrated. Run calibration first.\")\n",
    "else:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print(\"Starting live distance estimation. Press ESC to quit.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        results = model(frame)\n",
    "        annotated = results[0].plot()\n",
    "\n",
    "        for box in results[0].boxes.xywh:\n",
    "            w_pixels = box[2].item()\n",
    "            distance_inch = (KNOWN_WIDTH_INCH * FOCAL_LENGTH) / w_pixels\n",
    "            x, y = int(box[0]), int(box[1])\n",
    "            cv2.putText(annotated, f\"{distance_inch:.2f} in\", (x, y-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"YOLO Distance Estimation\", annotated)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # ESC to quit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import cv2\n",
    "\n",
    "# Convert BGR -> RGB for Jupyter display\n",
    "frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "clear_output(wait=True)\n",
    "display(frame_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5665ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "# --- Parameters ---\n",
    "MODEL_PATH = \"trained_yolo_model/ODM-ver5.pt\"\n",
    "KNOWN_WIDTH_INCH = 1.0        # Width of block\n",
    "ASSUMED_PIXEL_WIDTH = 100.0   # Approx width of block in pixels at ~12 inches\n",
    "FOCAL_LENGTH = (ASSUMED_PIXEL_WIDTH * 12.0) / KNOWN_WIDTH_INCH  # pixels\n",
    "\n",
    "# --- Load YOLO model ---\n",
    "model = YOLO(MODEL_PATH)\n",
    "print(\"✅ YOLO model loaded\")\n",
    "\n",
    "# --- Open camera ---\n",
    "cap = cv2.VideoCapture(\"/dev/video0\")  # change to /dev/video1 if needed\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "print(\"Starting live YOLO detection. Press ESC to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"❌ Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    start_time = time.time()\n",
    "    results = model(frame, verbose=False)  # run YOLO inference\n",
    "    end_time = time.time()\n",
    "\n",
    "    annotated = results[0].plot()  # draw bounding boxes\n",
    "\n",
    "    # Calculate distance for each detected block\n",
    "    for box in results[0].boxes.xywh:\n",
    "        w_pixels = box[2].item()\n",
    "        distance_inch = (KNOWN_WIDTH_INCH * FOCAL_LENGTH) / w_pixels\n",
    "        x, y = int(box[0]), int(box[1])\n",
    "        cv2.putText(annotated, f\"{distance_inch:.2f} in\", (x, y-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # Show FPS on frame\n",
    "    fps = 1 / (end_time - start_time)\n",
    "    cv2.putText(annotated, f\"FPS: {fps:.2f}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "    # Display\n",
    "    cv2.imshow(\"YOLO Distance Estimation\", annotated)\n",
    "\n",
    "    # Stop with ESC\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce28f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from IPython.display import display, clear_output\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# --- Parameters ---\n",
    "MODEL_PATH = \"trained_yolo_model/ODM-ver5.pt\"\n",
    "KNOWN_WIDTH_INCH = 1.0\n",
    "ASSUMED_PIXEL_WIDTH = 100.0\n",
    "FOCAL_LENGTH = (ASSUMED_PIXEL_WIDTH * 12.0) / KNOWN_WIDTH_INCH\n",
    "\n",
    "# --- Load YOLO model ---\n",
    "model = YOLO(MODEL_PATH)\n",
    "print(\"✅ YOLO model loaded\")\n",
    "\n",
    "# --- Open camera ---\n",
    "cap = cv2.VideoCapture(\"/dev/video0\")\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "print(\"Starting live YOLO detection. Press 'q' in input to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"❌ Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    start_time = time.time()\n",
    "    results = model(frame, verbose=False)\n",
    "    end_time = time.time()\n",
    "\n",
    "    annotated = results[0].plot()\n",
    "\n",
    "    # Calculate distance for each detected block\n",
    "    for box in results[0].boxes.xywh:\n",
    "        w_pixels = box[2].item()\n",
    "        distance_inch = (KNOWN_WIDTH_INCH * FOCAL_LENGTH) / w_pixels\n",
    "        x, y = int(box[0]), int(box[1])\n",
    "        cv2.putText(annotated, f\"{distance_inch:.2f} in\", (x, y-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    fps = 1 / (end_time - start_time)\n",
    "    cv2.putText(annotated, f\"FPS: {fps:.2f}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "    # Convert for Jupyter display\n",
    "    annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)\n",
    "    clear_output(wait=True)\n",
    "    display(annotated_rgb)\n",
    "\n",
    "    key = input(\"Press Enter to continue or 'q' to quit: \").lower()\n",
    "    if key == 'q':\n",
    "        break\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab73cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "# --- Parameters ---\n",
    "MODEL_PATH = \"trained_yolo_model/ODM-ver5.pt\"\n",
    "KNOWN_WIDTH_INCH = 1.0\n",
    "ASSUMED_PIXEL_WIDTH = 100.0\n",
    "FOCAL_LENGTH = (ASSUMED_PIXEL_WIDTH * 12.0) / KNOWN_WIDTH_INCH\n",
    "\n",
    "# --- Load YOLO model ---\n",
    "model = YOLO(MODEL_PATH)\n",
    "print(\"✅ YOLO model loaded\")\n",
    "\n",
    "# --- Open camera ---\n",
    "cap = cv2.VideoCapture(\"/dev/video0\")\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "print(\"Running YOLO + distance estimation (headless). Press Ctrl+C to stop.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"❌ Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        start_time = time.time()\n",
    "        results = model(frame, verbose=False)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate distance for each detected block\n",
    "        distances = []\n",
    "        for box in results[0].boxes.xywh:\n",
    "            w_pixels = box[2].item()\n",
    "            distance_inch = (KNOWN_WIDTH_INCH * FOCAL_LENGTH) / w_pixels\n",
    "            distances.append(distance_inch)\n",
    "\n",
    "        # Print results\n",
    "        if distances:\n",
    "            print(f\"Detected {len(distances)} block(s), distances (inches): {[round(d, 2) for d in distances]}\")\n",
    "\n",
    "        fps = 1 / (end_time - start_time)\n",
    "        print(f\"FPS: {fps:.2f}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped by user\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    print(\"Camera released\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d55eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "# --- Parameters ---\n",
    "MODEL_PATH = \"trained_yolo_model/ODM-ver5.pt\"\n",
    "KNOWN_WIDTH_INCH = 1.0\n",
    "ASSUMED_PIXEL_WIDTH = 100.0\n",
    "FOCAL_LENGTH = (ASSUMED_PIXEL_WIDTH * 12.0) / KNOWN_WIDTH_INCH\n",
    "\n",
    "# --- Load YOLO model ---\n",
    "model = YOLO(MODEL_PATH)\n",
    "print(\"✅ YOLO model loaded\")\n",
    "\n",
    "# --- Open camera ---\n",
    "cap = cv2.VideoCapture(\"/dev/video0\")\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "print(\"Running YOLO + distance estimation headless for 10 seconds...\")\n",
    "\n",
    "start_time_total = time.time()\n",
    "snapshot_count = 0\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"❌ Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        start_time = time.time()\n",
    "        results = model(frame, verbose=False)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate distance for each detected block\n",
    "        distances = []\n",
    "        for box in results[0].boxes.xywh:\n",
    "            w_pixels = box[2].item()\n",
    "            distance_inch = (KNOWN_WIDTH_INCH * FOCAL_LENGTH) / w_pixels\n",
    "            distances.append(distance_inch)\n",
    "\n",
    "        # Print results\n",
    "        if distances:\n",
    "            print(f\"Detected {len(distances)} block(s), distances (inches): {[round(d,2) for d in distances]}\")\n",
    "\n",
    "        fps = 1 / (end_time - start_time)\n",
    "        print(f\"FPS: {fps:.2f}\")\n",
    "\n",
    "        # Save snapshot every 5 frames\n",
    "        snapshot_count += 1\n",
    "        if snapshot_count % 5 == 0:\n",
    "            cv2.imwrite(f\"frame_{snapshot_count}.jpg\", frame)\n",
    "            print(f\"Saved frame_{snapshot_count}.jpg\")\n",
    "\n",
    "        # Stop after 10 seconds\n",
    "        if time.time() - start_time_total >= 10:\n",
    "            print(\"⏱ 10 seconds elapsed, stopping...\")\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped by user\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    print(\"Camera released\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a868c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook-friendly installation of Picamera2 and dependencies\n",
    "!sudo apt update\n",
    "!sudo apt install -y python3-picamera2 python3-libcamera python3-numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import os\n",
    "\n",
    "# --- Parameters ---\n",
    "MODEL_PATH = \"trained_yolo_model/ODM-ver5.pt\"\n",
    "KNOWN_WIDTH_INCH = 1.0            # Width of block in inches\n",
    "ASSUMED_PIXEL_WIDTH = 100.0       # Approx width of block in pixels at ~12 inches\n",
    "FOCAL_LENGTH = (ASSUMED_PIXEL_WIDTH * 12.0) / KNOWN_WIDTH_INCH\n",
    "\n",
    "SAVE_DIR = \"snapshots\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- Load YOLO model ---\n",
    "model = YOLO(MODEL_PATH)\n",
    "print(\"✅ YOLO model loaded\")\n",
    "\n",
    "# --- Open camera ---\n",
    "cap = cv2.VideoCapture(0)  # 0 = default camera\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(\"❌ Could not open camera. Make sure a camera is connected.\")\n",
    "\n",
    "print(\"Running YOLO + distance estimation headless for 10 seconds...\")\n",
    "\n",
    "start_time_total = time.time()\n",
    "snapshot_count = 0\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            print(\"❌ Failed to grab frame\")\n",
    "            continue\n",
    "\n",
    "        # Run YOLO\n",
    "        start_time = time.time()\n",
    "        results = model(frame, verbose=False)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate distances\n",
    "        distances = []\n",
    "        for box in results[0].boxes.xywh:\n",
    "            w_pixels = box[2].item()\n",
    "            distance_inch = (KNOWN_WIDTH_INCH * FOCAL_LENGTH) / w_pixels\n",
    "            distances.append(distance_inch)\n",
    "\n",
    "        # Print detected distances\n",
    "        if distances:\n",
    "            print(f\"Detected {len(distances)} block(s), distances (inches): {[round(d,2) for d in distances]}\")\n",
    "\n",
    "        fps = 1 / (end_time - start_time)\n",
    "        print(f\"FPS: {fps:.2f}\")\n",
    "\n",
    "        # Save snapshot every 5 frames\n",
    "        snapshot_count += 1\n",
    "        if snapshot_count % 5 == 0:\n",
    "            filepath = os.path.join(SAVE_DIR, f\"frame_{snapshot_count}.jpg\")\n",
    "            success = cv2.imwrite(filepath, frame)\n",
    "            if success:\n",
    "                print(f\"✅ Saved {filepath}\")\n",
    "            else:\n",
    "                print(f\"❌ Failed to save {filepath}\")\n",
    "\n",
    "        # Stop after 10 seconds\n",
    "        if time.time() - start_time_total >= 10:\n",
    "            print(\"⏱ 10 seconds elapsed, stopping...\")\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped by user\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    print(\"Camera released\")\n",
    "    print(\"Snapshots saved in folder:\", os.path.abspath(SAVE_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8a081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
